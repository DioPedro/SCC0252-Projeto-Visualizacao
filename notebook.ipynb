{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualização de Dados Covid 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alunos\n",
    "Alexandre Brito Gomes - 11857323\n",
    "\n",
    "Diógenes Silva Pedro - 11883476\n",
    "\n",
    "Gabriel Freitas Ximenes Vasconcelos - 11819084"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste visualização, analisaremos o conjunto de dados \"Coronavirus - Brazil\", disponível no Kaggle em https://www.kaggle.com/datasets/unanimad/corona-virus-brazil?select=brazil_covid19_cities.csv . Nele, é possível obter informações sobre o número de casos de Coronavirus no Brasil de maneira temporal: apresentando o número de casos, de maneira cumulativa, desde 30 de janeiro de 2020, quando o primeiro caso suspeito foi encontrado no país. \n",
    "\n",
    "Esse conjunto de dados é composto por 6 arquivos csv, contendo dados como latitude e longitude das cidades, data da confirmação de primeiro caso, número de casos confirmados, número de mortes, recuperados, suspeitos, entre diversos outros.\n",
    "\n",
    "Com isso, é possível fazer análises como verificação de quais localidades tiveram maiores números de casos em pouco tempo, como foi a evolução dos casos ao longo do tempo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação dos datasets base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'covid-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population = pd.read_csv(data_path + 'brazil_population_2019.csv')\n",
    "df_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities = pd.read_csv(data_path + \"brazil_covid19_cities.csv\")\n",
    "df_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coordinates = pd.read_csv(data_path + \"brazil_cities_coordinates.csv\")\n",
    "df_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação do df_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city = df_cities.merge(df_population[['city', 'population', 'region']], how='inner', left_on = 'name', right_on='city')\n",
    "df_city = df_city.merge(df_coordinates[['city_name', 'city_code', 'lat', 'long']], how='inner', left_on='name', right_on='city_name')\n",
    "df_city = df_city.drop([\"code\", \"name\", \"city_name\"], axis='columns')\n",
    "df_city.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city.sort_values(['city', 'date'], inplace=True)\n",
    "df_city.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolver o problema da acumulação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As colunas `death` e `mortes` são colunas que idealmente deveriam ser acumuladas. No entanto, ao analisar o dataset podemos ver que há casos em que valores diminuem.\n",
    "O dataset possui 2770 municípios e apenas 266 não possuem esse problema, por isso, devemos dar a devida atenção a esse problema nos dados.\n",
    "\n",
    "Para amenizar isso, criamos a função `fix_accumulation` que funciona da seguinte maneira:\n",
    "\n",
    "1. Defino como `start` a posição cuja a posição seguinte é um valor menor\n",
    "2. Percorro o array até achar uma posição cujo valor é igual ou superior ao valor do `start`. Essa posição é a `end`\n",
    "3. Vejo a quantidade de elementos entre `start` e `end` e faço a seguinte equação que representa o coeficiente angular da reta:\n",
    "   $$\n",
    "   \\Delta y = \\frac{\\text{arr[end]} - \\text{arr[start]}}{\\text{end}-\\text{start}}\n",
    "   $$\n",
    "4. Incremento $\\Delta y$ a partir de cada valor, começando de `start` até chegar ao `end`\n",
    "5. Caso um `start` comece e o array termine antes de chegar ao `end`, os valores seguintes ao `start` são substituídos por ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_accumulation(original_arr):\n",
    "    arr = original_arr.copy()\n",
    "    prev = arr[0]\n",
    "    start = 0\n",
    "    end = 0\n",
    "    interval = False\n",
    "    for i, el in enumerate(arr):\n",
    "        if el < prev and interval == False:\n",
    "            start = i-1\n",
    "            interval = True\n",
    "            \n",
    "        if el >= arr[start] and interval == True:\n",
    "            end = i\n",
    "            interval=False\n",
    "            delta = (arr[end]-arr[start])/(end-start)\n",
    "            for j in range(start+1, end):\n",
    "                arr[j] = int(math.floor(arr[j-1] + delta))\n",
    "                \n",
    "        prev = arr[i]\n",
    "        \n",
    "    if interval == True:\n",
    "        for i in range(start+1, len(arr)):\n",
    "            arr[i] = arr[start]\n",
    "            \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solucionar_coluna(coluna):\n",
    "    # Cidades que possuem esse problema\n",
    "    problemas = list(df_city.loc[df_city[coluna + ' per day'] < 0].drop_duplicates(subset=['city'], inplace=False)[\"city\"])\n",
    "    print(f\"Cidades com o problema na coluna {coluna}: {len(problemas)}\")\n",
    "    \n",
    "    # lista de índices das linhas de cidades com problemas\n",
    "    index_list = df_city.loc[df_city['city'].isin(problemas)].index\n",
    "    \n",
    "    # Crio uma lista de listas em que cada lista interna são as linhas de uma cidade\n",
    "    lists_of_cases = [g.values.tolist() for _, g in df_city.loc[df_city['city'].isin(problemas)].groupby(df_city['city'])[coluna]]\n",
    "    \n",
    "    # Aplico o fix_accumulation para cada cidade\n",
    "    fixed_cases = [fix_accumulation(city) for city in lists_of_cases]\n",
    "    \n",
    "    # Corrigo a coluna cases para cada cidade\n",
    "    index_start = 0\n",
    "    for fixed_city in fixed_cases:\n",
    "        city_indexes = index_list[index_start: index_start + len(fixed_city)]\n",
    "        index_start += len(fixed_city)\n",
    "        df_city.loc[city_indexes, coluna]=fixed_city\n",
    "        \n",
    "    # Quantidade de cidades com acumulação incorreta\n",
    "    problemas = df_city.loc[df_city[coluna + ' per day'] < 0].drop_duplicates(subset=['city']).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos as colunas `cases per day` e `mortes per day` para sabermos onde isso dá problema\n",
    "\n",
    "cum_columns = ['cases', 'deaths']\n",
    "df_city = df_city.merge(\n",
    "    df_city.groupby('city')[cum_columns].diff(),\n",
    "    left_index=True, right_index=True, suffixes=['', ' per day']\n",
    ").fillna({'{} per day'.format(cum_column): df_city[cum_column] for cum_column in cum_columns})\n",
    "\n",
    "df_city.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solucionar_coluna(\"cases\")\n",
    "solucionar_coluna(\"deaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropo as colunas antigas incorretas\n",
    "df_city = df_city.drop(columns=['cases per day', 'deaths per day'])\n",
    "\n",
    "# recrio as colunas só que com a agregação correta\n",
    "cum_columns = ['cases', 'deaths']\n",
    "df_city = df_city.merge(\n",
    "    df_city.groupby('city')[cum_columns].diff(),\n",
    "    left_index=True, right_index=True, suffixes=['', ' per day']\n",
    ").fillna({'{} per day'.format(cum_column): df_city[cum_column] for cum_column in cum_columns})\n",
    "\n",
    "df_city.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifico se não há nenhuma coluna com problema de acumulação após o processamento\n",
    "quant_cases = df_city.loc[df_city['cases per day'] < 0].drop_duplicates(subset=['city']).shape[0]\n",
    "quant_deaths = df_city.loc[df_city['deaths per day'] < 0].drop_duplicates(subset=['city']).shape[0]\n",
    "print(f\"Cidades com o problema na coluna cases após correção: {quant_cases}\")\n",
    "print(f\"Cidades com o problema na coluna deaths após correção: {quant_deaths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenho uma normalização por meio do tamanho da população da cidade\n",
    "df_city[\"cases/population\"] = df_city[\"cases\"]/df_city[\"population\"]\n",
    "df_city[\"deaths/population\"] = df_city[\"deaths\"]/df_city[\"population\"]\n",
    "df_city[\"cases per day/population\"] = df_city[\"cases per day\"]/df_city[\"population\"]\n",
    "df_city[\"deaths per day/population\"] = df_city[\"deaths per day\"]/df_city[\"population\"]\n",
    "\n",
    "df_city.rename(columns={'long': 'lon'}, inplace=True)\n",
    "\n",
    "df_city.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do df_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenho o número de casos e mortes por dia por estado\n",
    "df_state = df_city.groupby(['state', 'date'])[['cases per day', 'deaths per day']].sum()\n",
    "df_state.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adiciono a população do estado, somando as populações dos municípios do estado\n",
    "state_population = df_city.drop_duplicates(subset=['city']).groupby('state')['population'].sum()\n",
    "population_dict = state_population.to_dict()\n",
    "\n",
    "def add_population(row):\n",
    "    return population_dict[row['state']]\n",
    "\n",
    "df_state['population'] = df_state.apply(add_population, axis=1)\n",
    "df_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculo uma média da latitude e longitude dos municípios do estado\n",
    "state_avg_coord = df_city.drop_duplicates(subset=['city']).groupby('state')[['lat', 'lon']].mean()\n",
    "\n",
    "# adiciono a lat e long média, além de adicionar a região do estado\n",
    "df_state = df_state.merge(state_avg_coord, on='state').merge(df_city[['state', 'region']].drop_duplicates(subset=['state']), on='state')\n",
    "\n",
    "# calculo e adiciono o número de casos e mortes acumulados do estado\n",
    "df_state['cases'] = df_state.groupby('state')['cases per day'].cumsum(axis=0)\n",
    "df_state['deaths'] = df_state.groupby('state')['deaths per day'].cumsum(axis=0)\n",
    "\n",
    "# Obtenho uma normalização por meio do tamanho da população do estado\n",
    "df_state[\"cases/population\"] = df_state[\"cases\"]/df_state[\"population\"]\n",
    "df_state[\"deaths/population\"] = df_state[\"deaths\"]/df_state[\"population\"]\n",
    "df_state[\"cases per day/population\"] = df_state[\"cases per day\"]/df_state[\"population\"]\n",
    "df_state[\"deaths per day/population\"] = df_state[\"deaths per day\"]/df_state[\"population\"]\n",
    "df_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities_coordinates = pd.read_csv(data_path + \"brazil_cities_coordinates.csv\")\n",
    "df_cities_coordinates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brazil = pd.read_csv(data_path + \"brazil_cities_coordinates.csv\")\n",
    "df_brazil.loc[df_brazil[\"city_name\"] == 'Acrelândia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazil_code = 100\n",
    "with urlopen(f'https://raw.githubusercontent.com/tbrugz/geodata-br/master/geojson/geojs-{brazil_code}-mun.json') as response:\n",
    "    brazil_json = json.loads(response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city.loc[df_city['date'] == '2020-11-23'].describe()\n",
    "df_city['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city.loc[(df_city['date'] == '2020-05-23') & (df_city['city'] == 'São Carlos') & (df_city['state'] == 'SP') & (df_city['region'] == 'Sudeste')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city.iloc[1444582]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city.loc[(df_city['city'] == 'São Carlos')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth_mapbox(df_city.iloc[1444582-1: 1444582+1], geojson=brazil_json, featureidkey = 'properties.id', locations='city_code', color='deaths',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=9, center = df_city.iloc[1444582][[\"lat\", \"lon\"]].to_dict(),\n",
    "                           opacity=0.5\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
